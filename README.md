<h1 align="center">ğŸ“ UChicago Playground (2023-2025)</h1>
<p align="center"><em>"Efforts, Partial and Unsatisfactory"</em> at Ryerson Floor 2, UChicago</p>

My economics professor in college once told me that UChicago is a sacred place for academic pursuit. Later, my first advisor at UChicago said he hoped that something of UChicago would stay with me. Looking back on my three-year journeyâ€”one year as an undergrad RA at Chicago Booth and two years of master's studyâ€”this has been an intensive but deeply rewarding experience. It transformed me from a traditional data-driven machine learning researcher into a more thoughtful and responsible AI practitioner.

At this turning point, I want to take a moment to reflect and summarize my experiences in this repository. Beyond formal publications, many projects hereâ€”though small or experimentalâ€”capture somekey â€œahaâ€ moments throughout this journey.

Due to time constraints, I've mainly included structured outputs (e.g., reports, code, posters) related to AI topics. But Iâ€™ve also gained so much solid training in proof-based statistics during my first-year master study and hope to eventually convert my handwritten notes into LaTeX versionsâ€”though I still enjoy the charm of writing by hand! ğŸ¤¡

### ğŸ“‹ Coding-intensive Course Summary

| Course Number         | Course Name                                 | Keywords                                      | Output                 |
|-----------------------|---------------------------------------------|-----------------------------------------------|----------------------|
| BUSN 32200/32810 | [Artificial Intelligence](#ta-artificial-intelligence)                     | Comprehensive Survey of AI: From Academia to Industry to Society          | TA (Creating Course Materials)          |
| CMSC 35200            | [Deep Learning Systems](#deep-learning-systems)                    |             | Pilot Project (Clinical NLP)       |
| CMSC 35401            | [Human-Centered AI](#human-centered-ai)                           | Weak-to-Strong Generalization, Alignment             | Toy Project (Financial NLP)       |
| DATA 37784            | [Representation Learning in Machine Learning](#representation-learning-in-machine-learning)| Model Editing, Causal Representation Learning| Toy poject (Interpretability)      |
| CMSC 35440            | [Machine Learning in Biology and Medicine](#machine-learning-in-biology-and-medicine)                  |        | Coding Assignments (Python)       |
| STAT 31900            | [Introduction to Causal Inference](#introduction-to-causal-inference)            |         | Coding Assignments (R)        |
| FINM 32950            | [Introduction to High Performance Computing (HPC)](#introduction-to-high-performance-computing-hpc)   |              | Coding Assignments (C++)       |

---

## (TA) Artificial Intelligence
ğŸ”— [ğŸ“š Reading Materials](https://github.com/YuyangJ0/UChicago-Playground/tree/main/BUSN_32200) 

- **Instructor:** Dacheng Xiu, Booth School of Business  
- **Comment:**  


## Deep Learning Systems  
ğŸ”— [ğŸ©» Poster](https://github.com/YuyangJ0/UChicago-Playground/blob/main/CMSC_35200/poster_24x36.pdf)â€ƒğŸ”— [ğŸ“„ Report](https://github.com/YuyangJ0/UChicago-Playground/blob/main/CMSC_35200/Evaluator_report_20241212.pdf)â€ƒğŸ”— [ğŸ’» Code]

- **Instructor:** Rick Stevens, Department of Computer Science  
- **Title:** Exploring the Potential of LLMs as Radiology Report Evaluator 
- **Abstract:** The rise of large language models (LLMs) has opened new possibilities in medical AI, particularly in evaluating radiology reports. This study explores the potential of LLMs as radiology report evaluators. Current evaluation frameworks for radiology report generation are often shallow and limited, leading to inconclusive results about AI systems' capabilities. To address this, we propose a comprehensive pipeline for evaluating generated reports using LLMs, grounded in tasks such as label extraction and clarity scoring. Our experiments demonstrate that LLMs consistently outperform state-of-the-art (SOTA) labelers in labeling accuracy and show promise in clarity evaluation, particularly when leveraging agentic collaboration like majority voting. However, challenges remain, including mixed results with prompt engineering strategies, the limitations of multi-step prompting, and failure to fully align with radiologists' preferences for filtering more readable reports. This work represents a step forward in developing a robust, LLM-based evaluation framework, ultimately aimed at enhancing the quality and reliability of radiology report generation pipelines.
- **Comment:** This is a pilot project that contributes to my second publication (Coming very soon in May!)


## Human-Centered AI  
ğŸ”— [ğŸ“„ Report](https://github.com/YuyangJ0/UChicago-Playground/blob/main/CMSC_35401/CMSC_35401_Final_report.pdf) ğŸ”— [ğŸ’» Code]â€ƒ

- **Instructor:** Chenhao Tan, Department of Computer Science  
- **Title:** Weak-to-Strong Generalization on Financial News Summarization
- **Abstract:** In this project, we investigate the applicability of the weak-to-strong generalization framework in the context of financial news summarization. We constructed a dataset of 2,000 financial news records and assessed the performance of OpenAI's framework from lexical and pragmatic viewpoints. Our findings indicate that: (1) the weak-to-strong generalization does not hold in the context of financial news summarization for the model classes tested; (2) while the summarization models like BART series more closely align with the ground truth compared to the text generation model LLaMA-1, they are less effective in producing financially informative summaries.
- **Comment:** This is a toy project that we adapt OpenAI's weak-to-strong generalization framework into a financial news summarisation task.


## Representation Learning in Machine Learning  
ğŸ”— [ğŸ“„ Proposal](https://github.com/YuyangJ0/UChicago-Playground/blob/main/DATA_37784/report.pdf) ğŸ”— [ğŸ’» Code]

- **Instructor:** Victor Veitch, Department of Statistics  
- **Title:** Locating Domain-specific Facts in Generative Pre-training Transformer (GPT)
- **Abstract:** 
- **Comment:** This is a toy project that was further inspired by my presented paper 


## Machine Learning in Biology and Medicine  
ğŸ”— [ğŸ“ Assignments]

- **Instructor:** Robert Grossman, Departments of Medicine & Computer Science  
- **Skill Sets:**  


## Introduction to Causal Inference  
ğŸ”— [ğŸ“ Assignments]

- **Instructor:** Guanglei Hong, Department of Comparative Human Development  
- **Skill Sets:**  


## Introduction to High Performance Computing (HPC)  
ğŸ”— [ğŸ“ Assignments]

- **Instructor:** Chanaka Liyanaarachchi, Department of Mathematics  
- **Skill Sets:**  


## ğŸ™‹â€â™€ï¸ Q&A 

If you encounter any issues or have suggestions for improvement, feel free to open an issue in this repository. I'm always happy and open to discuss further!


## ğŸ“„ License & Attribution

Â© 2025 Yuyang Jiang. All rights reserved.

This repository contains original work. Unauthorized copying, reuse, or distribution is prohibited. If you wish to reference or use this material, please contact me at kjiang4work@gmail.com. Thanks for your understanding!

