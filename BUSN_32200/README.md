### Data


### Foundation Model
1. [(DeepSeek, Dec, 2024) DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437)
2. [(Blog, Jan, 2025) DeepSeek V3 Training Cost: Here's How It Compares To Llama 3.1 (405B)](https://apxml.com/posts/training-cost-deepseek-v3-vs-llama-3)
3. [(Meta AI, July, 2024) The Llama 3 Herd of Models](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/)
4. [(Microsoft Talk, Andrej Karpathy, May, 2023) State of GPT](https://youtu.be/bZQun8Y4L2A?si=zsfiU-D553AVWOUi)
5. [Bommasani, Rishi, et al. "On the opportunities and risks of foundation models." arXiv preprint arXiv:2108.07258 (2021).](https://arxiv.org/abs/2108.07258)


### Scaling Law
1. [Kaplan, Jared, et al. "Scaling laws for neural language models." arXiv preprint arXiv:2001.08361 (2020).](https://arxiv.org/abs/2001.08361)


### Post-training
- Multi-modality
1. [(Meta AI, June 05, 2024) An Introduction to Vision-Language Modeling](https://ai.meta.com/research/publications/an-introduction-to-vision-language-modeling/)
2. [Liu, Haotian, et al. "Visual instruction tuning." Advances in neural information processing systems 36 (2023): 34892-34916.](https://arxiv.org/abs/2304.08485)
3. [Acosta, J.N., Falcone, G.J., Rajpurkar, P. et al. Multimodal biomedical AI. Nat Med 28, 1773–1784 (2022). https://doi.org/10.1038/s41591-022-01981-2](https://www.nature.com/articles/s41591-022-01981-2#citeas)
- RLHF
3. [(Chip Huyen Blog, May, 2023) RLHF: Reinforcement Learning from Human Feedback](https://huyenchip.com/2023/05/02/rlhf.html#rlhf_overview)
4. [Ouyang, Long, et al. "Training language models to follow instructions with human feedback." Advances in neural information processing systems 35 (2022): 27730-27744.](https://arxiv.org/abs/2203.02155)
5. [Chaudhari, Shreyas, et al. "Rlhf deciphered: A critical analysis of reinforcement learning from human feedback for llms." arXiv preprint arXiv:2404.08555 (2024).](https://arxiv.org/abs/2404.08555)
- Reasoning
6. [Xu, Fengli, et al. "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models." arXiv preprint arXiv:2501.09686 (2025).](https://arxiv.org/abs/2501.09686)
7. [(DeepSeek, Jan, 2025) DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
8. [(Blog, Feb, 2025) Comparison of Large Reasoning Models (LRMs)](https://medium.com/intuitionmachine/comparison-of-large-reasoning-models-lrms-dbc468d10906)


### Bias and Evaluation


### Societal AI
1. [Buolamwini, Joy, and Timnit Gebru. "Gender shades: Intersectional accuracy disparities in commercial gender classification." Conference on fairness, accountability and transparency. PMLR, 2018.](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf) (One of my first inspiring papers in AI! ✨)
2. [Bolukbasi, Tolga, et al. "Man is to computer programmer as woman is to homemaker? debiasing word embeddings." Advances in neural information processing systems 29 (2016).](https://arxiv.org/abs/1607.06520) (One of my first inspiring papers in AI! ✨)
3. [Kapoor, Sayash, et al. "On the societal impact of open foundation models." arXiv preprint arXiv:2403.07918 (2024).](https://arxiv.org/abs/2403.07918)
4. [(Stanford HAI, 2024) The 2024 AI Index Report](https://hai.stanford.edu/ai-index/2024-ai-index-report)